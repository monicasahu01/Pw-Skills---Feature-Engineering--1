{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1679c1d5-1888-48eb-8a14-439861177e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is the Filter method in feature selection, and how does it work?\n",
    "Ans- A feature is an attribute that has an impact on a problem or is useful for the problem, and \n",
    "choosing the important features for the model is known as feature selection. Each machine learning process \n",
    "depends on feature engineering, which mainly contains two processes; which are Feature Selection and Feature Extraction. \n",
    "Although feature selection and extraction processes may have the same objective, both are completely different from each other. \n",
    "The main difference between them is that feature selection is about selecting the subset of the original feature set, whereas \n",
    "feature extraction creates new features. \n",
    "Need for Feature Selection\n",
    "Before implementing any technique, \n",
    "it is really important to understand, need for the technique and so for the Feature Selection. As we know, in machine learning, \n",
    "it is necessary to provide a pre-processed and good input dataset in order to get better outcomes. We collect a huge amount of\n",
    "data to train our model and help it to learn better. Generally, the dataset consists of noisy data, irrelevant data, and some part of useful data. \n",
    "Moreover, the huge amount of data also slows down the training process of the model, and with noise and irrelevant data, the model may not predict \n",
    "and perform well. So, it is very necessary to remove such noises and less-important data from the dataset and to do this, and Feature selection techniques are used.\n",
    "Selecting the best features helps the model to perform well. \n",
    "For example, Suppose we want to create a model that automatically decides which car should be crushed for a spare part, and to do this, \n",
    "we have a dataset. This dataset contains a Model of the car, Year, Owner's name, Miles. So, in this dataset, the name of \n",
    "the owner does not contribute to the model performance as it does not decide if the car should be crushed or not, \n",
    "so we can remove this column and select the rest of the features(column) for the model building.\n",
    "Feature selection is a way of reducing the input variable for the model by using only relevant data in order to reduce overfitting in the model.\n",
    "\n",
    "Q2. How does the Wrapper method differ from the Filter method in feature selection?\n",
    "Ans- In wrapper methodology, selection of features is done by considering it as a search problem, \n",
    "in which different combinations are made, evaluated, and compared with other combinations. \n",
    "It trains the algorithm by using the subset of features iteratively.\n",
    "Some techniques of wrapper methods are:\n",
    "\n",
    "Forward selection - Forward selection is an iterative process, which begins with an empty set of features. \n",
    "After each iteration, it keeps adding on a feature and evaluates the performance to check whether it is improving the performance or not. \n",
    "The process continues until the addition of a new variable/feature does not improve the performance of the model.\n",
    "Backward elimination - Backward elimination is also an iterative approach, but it is the opposite of forward selection. \n",
    "This technique begins the process by considering all the features and removes the least significant feature. \n",
    "This elimination process continues until removing the features does not improve the performance of the model.\n",
    "Exhaustive Feature Selection- Exhaustive feature selection is one of the best feature selection methods,\n",
    " which evaluates each feature set as brute-force. It means this method tries & make each possible combination of \n",
    "features and return the best performing feature set.\n",
    "Recursive Feature Elimination-\n",
    "Recursive feature elimination is a recursive greedy optimization approach, \n",
    "where features are selected by recursively taking a smaller and smaller subset of features. \n",
    "Now, an estimator is trained with each set of features, and the importance of each feature is \n",
    "determined using coef_attribute or through a feature_importances_attribute.\n",
    "\n",
    "\n",
    "Q3. What are some common techniques used in Embedded feature selection methods?\n",
    "There are mainly two types of Feature Selection techniques, which are:\n",
    "\n",
    "Supervised Feature Selection technique\n",
    "Supervised Feature selection techniques consider the target variable and can be used for the labelled dataset.\n",
    "Unsupervised Feature Selection technique\n",
    "Unsupervised Feature selection techniques ignore the target variable and can be used for the unlabelled dataset.\n",
    "\n",
    "Q4. What are some drawbacks of using the Filter method for feature selection?\n",
    "Ans-The common disadvantage of filter methods is that they ignore the interaction with the classifier and each feature is \n",
    "considered independently thus ignoring feature dependencies In addition, it is not clear \n",
    "how to determine the threshold point for rankings to select only the required features and exclude noise\n",
    "\n",
    "Q5. In which situations would you prefer using the Filter method over the Wrapper method for feature\n",
    "selection?\n",
    "Ans-For large data you should use the Filter approaches because these approaches are rapid and for small size of data it is better to use Wrapper (KNN, SVM,...) \n",
    "approaches because they are slower than the Filter approaches. \n",
    "or you can combine the two approaches to have better results than the two approaches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
